# -*- coding: utf-8 -*-
"""Petrol-verileri.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K89TSWo2pkk8kUuurECTSvhbWyPEfjLA
"""

import csv
from google.colab import drive
drive.mount('/content/gdrive')
import pandas as pd
import numpy as np
import seaborn as sbn
import matplotlib.pyplot as plt

df = pd.read_excel('/content/gdrive/MyDrive/Colab Notebooks/dataset_petrol_ml/train_test.xlsx')
df= pd.DataFrame(df)
print(df)
#aşağıdaki isnull komutuyla verideki her bir sütunda ne kadar boş satır olduğunu görüyoruz
df.isnull().sum()

df = df.drop(df.columns[[0,3,4]], axis=1)
# yukarıdaki kodda içinde çok boşluk olan 3 ve 4. satır ile cerilen tarihlerini gösteren satırı veri setinden siliniyoruz. Son sütunu düşürmemizin nedeni bu veri setini eğitirken D ye göre eğitmek.
print(df)

df.describe()
# Aşağıdaki tabloda her bir sütındaki verilerin ortalama ve standart sapma gibi değerlerini görüyoruz.

# Aşağıdaki bütün satırlarda yaptığım işlem her bir sütundaki boşlukarı kendi ortalama değerleri ile doldurmak.
m1=df.Y1.mean()
df['Y1'] = df['Y1'].fillna(m1)
m2=df.Y2.mean()
df['Y2'] = df['Y2'].fillna(m2)
m3=df.A1.mean()
df['A1'] = df['A1'].fillna(m3)
m4=df.Y3.mean()
df['Y3'] = df['Y3'].fillna(m4)
m5=df.Y5.mean()
df['Y4'] = df['Y4'].fillna(m5)
m6=df.Y5.mean()
df['Y5'] = df['Y5'].fillna(m6)
m7=df.Y6.mean()
df['Y6'] = df['Y6'].fillna(m7)
m8=df.U1.mean()
df['U1'] = df['U1'].fillna(m8)
m9=df.U2.mean()
df['U2'] = df['U2'].fillna(m9)
m10=df.D.mean()
df['D'] = df['D'].fillna(m10)
df.isnull().sum()

plt.figure()
sbn.distplot(df["Y1"])
plt.figure()
sbn.distplot(df["Y2"])
plt.figure()
sbn.distplot(df["Y3"])
plt.figure()
sbn.distplot(df["Y4"])
plt.figure()
sbn.distplot(df["Y5"])
plt.figure()
sbn.distplot(df["Y6"])
plt.figure()
sbn.distplot(df["A1"])
plt.figure()
sbn.distplot(df["U1"])
plt.figure()
sbn.distplot(df["U2"])
plt.figure()
sbn.distplot(df["O1"])
plt.figure()
sbn.distplot(df["O2"])
#Aşagıdaki grafikler test değerleriniin en çok hangi değerlerde yoğunlaştıklarını gösterir. Bazı değerler belli bir aralıkta düzgün bir şekilde yoğunlaşmıştır.Buda model eğitiminde ve test yaparken  kolaylık sağlar.
#Fakat böyle değerler farklı bir veri değeri geldiğinde doğru hesaplama yapamayabilir.
# O1 gibi veri değerleri belli bir aralıkta değilde çeşitli değerde yoğunlşamalar gösterir. Bu tip test verisini eğitmemiz için farklı tip modelleri denemek gerekebilir. Fakat bu tip veri setleri modelden tahmin yaparken  daha doğru test sonucları elde edebilmemizi sağlar.

df.corr()
# Burada veri setimizi eğitirken en çok hangi sutunların önemli olacağını yada en az hangi verilerin ekili olacağını yani aralarındaki korelasyonu görüyoruz.

y =  df["D"].values
x = df.drop(df.columns[11], axis=1).values
print(y)
print(x)
# Buradaki x ve y değerleri modelimizi eğitirken ihtiyacımız olacak train ve test verilerini böleceğimiz değerler.

from sklearn.model_selection import train_test_split
x_train,  x_test , y_train , y_test=train_test_split(x,y,test_size=0.33,random_state=15) #x ve y değerleinden train ve test verileirni sklearn kütüphanesi sayesinde elde ediyoruz.
#test size =0.33 değeri toplam verinin yaklaşık olarak 1/3 ünü test için 2/3 ünüde train için ayırır.

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)
#x_tarin ve x_test verilerini 0 ile 1 arasında çeşitli değerlere scaler ediyoruz.
print(x_train.shape)
print(y_train.shape)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()

model.add(Dense(12,activation="relu"))
model.add(Dense(12,activation="relu"))
model.add(Dense(12,activation="relu"))
model.add(Dense(12,activation="relu"))
model.add(Dense(12,activation="relu"))

model.add(Dense(1))

model.compile(optimizer="adam",loss="mse")
# Modelin katmanlarını ve kullanılacak olan parametreleri etkin hale getiriyorum

model.fit(x=x_train, y = y_train,validation_data=(x_test,y_test),batch_size=150,epochs=400)
#model.fit ile modeli eğitiyorum.

train_loss=model.evaluate(x_train,y_train,verbose=0)
test_loss=model.evaluate(x_test,y_test,verbose=0)
#loss değerlerinin değerlendirmesini yapıyoruz.
print("train loss",train_loss)
print("test loss",test_loss)

testTahminleri=model.predict(x_test)
print(testTahminleri)

tahminDf=pd.DataFrame(y_test,columns=["Gerçek D"])
testTahminleri=pd.Series(testTahminleri.reshape()) # burada testTahminleri olarak elde ettiğimiz değerleri arrayden data frame'e çeviriyoruz.
tahminDf = pd.concat([tahminDf,testTahminleri],axis=1) # testTahminlerini gerçek D değerinin yanına sutün olarak birleştiriyoruz. Tahminlerin doğru olup olmadığını daha kolay görebilmek için.
tahminDf.columns=["gerçek D"," Tahmin D"]
tahminDf

from sklearn.metrics import mean_absolute_error,mean_squared_error

mse=mean_absolute_error(tahminDf["gerçek D"],tahminDf[" Tahmin D"])
print(mse)

# Calculation of Mean Squared Error (MSE)
mean_squared_error(tahminDf["gerçek D"],tahminDf[" Tahmin D"])

#Buradan sonra prediction test verisini düzenli hale getirerek veriyi  eğittiğim modele vererek D değerelerini hesaplattım.
prediction= pd.read_excel('/content/gdrive/MyDrive/Colab Notebooks/dataset_petrol_ml/prediction.xlsx')
predictionDf = pd.DataFrame(prediction)
predictionDf

predictionDf = predictionDf.drop(predictionDf.columns[[0,3,4]], axis=1)
predictionDf

predictionDf.isnull().sum()

m1=predictionDf.Y1.mean()
predictionDf['Y1'] = predictionDf['Y1'].fillna(m1)
m2=predictionDf.Y2.mean()
predictionDf['Y2'] = predictionDf['Y2'].fillna(m2)
m3=predictionDf.A1.mean()
predictionDf['A1'] = predictionDf['A1'].fillna(m3)
m4=predictionDf.Y3.mean()
predictionDf['Y3'] = predictionDf['Y3'].fillna(m4)
m5=predictionDf.Y5.mean()
predictionDf['Y4'] = predictionDf['Y4'].fillna(m5)
m6=predictionDf.Y5.mean()
predictionDf['Y5'] = predictionDf['Y5'].fillna(m6)
m7=predictionDf.Y6.mean()
predictionDf['Y6'] = predictionDf['Y6'].fillna(m7)
m6=predictionDf.U1.mean()
predictionDf['U1'] = predictionDf['U1'].fillna(m6)
m7=predictionDf.U2.mean()
predictionDf['U2'] = predictionDf['U2'].fillna(m7)

predictionDf.isnull().sum()

yeniPredictionDf= scaler.transform(predictionDf)

model.predict(yeniPredictionDf)

